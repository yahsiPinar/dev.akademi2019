{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "devakademi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twBKUcfepNkx",
        "colab_type": "text"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlsc4NEDo7Ly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import plotly.express as px\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quZ_cr6GBgLh",
        "colab_type": "text"
      },
      "source": [
        "# Read JSON and convert it to a dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR2X9u4kuup_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "openfile=open('bulkV2.json')\n",
        "jsondata=json.load(openfile)\n",
        "df=pd.DataFrame(jsondata)\n",
        "openfile.close()\n",
        "#df.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GthwsEMCBnmg",
        "colab_type": "text"
      },
      "source": [
        "# Create a subset that includes 3 columns: description,title,price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjuK8PVx6GKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subset = df.loc[df['c1'] == 'Otomobil']\n",
        "subset = subset[['c0','c1','c2','description','title','price']] \n",
        "#subset\n",
        "del(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRWq_HDjBxGo",
        "colab_type": "text"
      },
      "source": [
        "# Clean the dirty data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvOwyuJs6OcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(reviewText):\n",
        "  reviewText = reviewText.str.replace(\"(<u>)\", \"\")\n",
        "  reviewText = reviewText.str.replace(\"(\\t)\", \"\")\n",
        "  reviewText = reviewText.str.replace(\"(\\n)\", \"\")\n",
        "  reviewText = reviewText.str.replace(\"<.*?>\", \"\")\n",
        "  return reviewText\n",
        "  \n",
        "subset['description'] = preprocess(subset['description'])\n",
        "subset.index = range(0,len(subset))\n",
        "#subset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spJwHzEJ_4JJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#subset.to_csv (r'export_dataframe.csv', index = None, header=True) # this line saves the dataframe as .csv file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGocRt9HhxHx",
        "colab_type": "code",
        "outputId": "42b4dcbb-0c22-40e9-df63-cb7768f25f01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "median = subset['price'].median()\n",
        "lowerBound = subset.loc[subset['price']<=median]\n",
        "firstQuartile = lowerBound['price'].median()\n",
        "upperBound = subset.loc[subset['price']>=median]\n",
        "thirdQuartile = upperBound['price'].median()\n",
        "IQR = thirdQuartile-firstQuartile\n",
        "minimumPrice = max(firstQuartile - 1.5*IQR,subset['price'].min())\n",
        "maximumPrice = min(thirdQuartile + 1.5*IQR,subset['price'].max())\n",
        "print(median,firstQuartile,thirdQuartile,IQR,minimumPrice,maximumPrice)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48500.0 30000.0 76500.0 46500.0 6000.0 146250.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11YfiGo26QZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#datas in the interquartile range\n",
        "normalDistOfDataframe = subset.loc[(subset['price']>=minimumPrice)]\n",
        "normalDistOfDataframe = subset.loc[(subset['price']<=maximumPrice)]\n",
        "normalDistOfDataframe.index = range(0,len(normalDistOfDataframe))\n",
        "#normalDistOfDataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaF_oN0eB4s2",
        "colab_type": "text"
      },
      "source": [
        "# Find most using 25 words in document (Vakit kalınca dönecektim word frequency'leri göstermek için fakat yetmedi.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xinf_-ZuBRBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# def get_top_n_words(corpus,n=None):\n",
        "#   vec = CountVectorizer().fit(corpus)\n",
        "#   bag_of_words = vec.transform(corpus)\n",
        "#   sum_words = bag_of_words.sum(axis=1)\n",
        "#   word_freq = [(word, sum_words[0,idx]) for word,idx in vec.vocabulary_.items()]\n",
        "#   word_freq = sorted(word_freq, key = lambda x:x[1], reverse=True)\n",
        "#   return word_freq[:n]\n",
        "\n",
        "\n",
        "# common_words = get_top_n_words(subset['title'],25)\n",
        "# df_common_words = pd.DataFrame(common_words, columns=['word','frequency'])\n",
        "# fig = px.bar(df_common_words, x='word', y='frequency', hover_data= ['word','frequency'] ,color='frequency',\n",
        "#             title = 'İlan tanımlarında en çok kullanılan 25 kelime',height=400)\n",
        "# fig.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlcmCBsoQW4k",
        "colab_type": "text"
      },
      "source": [
        "Burada tüm ilan başlıkları tek bir listede toplanıyor ve daha sonra Tf-Idf ile her bir kelimenin dökümanın içerisindeki değeri belirleniyor. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIItyRw8PUmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del(subset)\n",
        "x_data = normalDistOfDataframe[['c0','c1','c2','description','title']]\n",
        "#version1: ram bittiği için hem ilan başlığı hemde tanımı ile yapamadım. Yorum olarak bırakıyorum.\n",
        "#titles = []\n",
        "# descriptions = []\n",
        "corpus = []\n",
        "# for i in range(0,len(x_data)):\n",
        "#   descriptions.append(x_data.iloc[i,3])\n",
        "#   titles.append(x_data.iloc[i,4])\n",
        "#   corpus.append(titles[i]+\" \"+ descriptions[i])\n",
        "\n",
        "#verison2: sadece ilan başlığı ile yaptığım hali.\n",
        "for i in range(0,len(x_data)):\n",
        "  corpus.append(x_data.iloc[i,4])\n",
        "  \n",
        "del(x_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yD0cXIfOI8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vec = tf().fit(corpus)\n",
        "vec = vec.transform(corpus)\n",
        "x = vec.toarray()\n",
        "y = normalDistOfDataframe['price']\n",
        "del(vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnX-SlLjUgcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state=39)\n",
        "del(x)\n",
        "del(y)\n",
        "#print(len(x_train), len(x_test),len(y_train),len(y_test))\n",
        "#y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9-eIt_RcNLZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "4b36dd7f-7fae-404b-cfb4-4cfbc9f83eff"
      },
      "source": [
        "randomForest = RandomForestRegressor(n_estimators=20)\n",
        "randomForest.fit(x_train,y_train)\n",
        "predicted = randomForest.predict(x_test)\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, predicted))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, predicted))\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, predicted)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 18601.759239088486\n",
            "Mean Squared Error: 646593211.2231296\n",
            "Root Mean Squared Error: 25428.197168166083\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}